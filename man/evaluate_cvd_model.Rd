% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluate_cvd_model.R
\name{evaluate_cvd_model}
\alias{evaluate_cvd_model}
\title{Evaluate CVD Model Performance (BIO215 Required Metrics)}
\usage{
evaluate_cvd_model(model_obj)
}
\arguments{
\item{model_obj}{A list from \code{train_cvd_rf()} containing:
\itemize{
\item \code{model}: Trained random forest model.
\item \code{test_data}: Hold-out test set (unseen data for unbiased evaluation).
\item \code{positive_level}: Positive class label ("CVD").
}}
}
\value{
A list with 6 components for report/dashboard use:
\itemize{
\item \code{confusion_matrix}: Confusion matrix (from \code{caret}) with accuracy, sensitivity, specificity.
\item \code{auroc}: Numeric value of AUROC (Area Under ROC Curve, range: 0-1).
\item \code{auprc}: Numeric value of AUPRC (Area Under Precision-Recall Curve, range: 0-1).
\item \code{feature_importance}: \code{tibble} of feature importance (sorted by permutation importance).
\item \code{roc_curve_data}: \code{data.frame} for ROC plot (FPR vs TPR).
\item \code{pr_curve_data}: \code{data.frame} for PR plot (Recall vs Precision).
}
}
\description{
Computes and returns all BIO215-mandated ML performance metrics for classification:
AUROC, AUPRC, accuracy, confusion matrix, and feature importance. Generates interpretable
outputs for the project research report (Results section) and README.
}
\details{
Aligns with BIO215 rubrics for ML model interpretation and reporting:
\enumerate{
\item \strong{Required Metrics}:
\itemize{
\item Classification: AUROC, AUPRC, accuracy, confusion matrix (sensitivity/specificity).
\item Model Interpretation: Feature importance (permutation-based, more reliable than impurity).
}
\item \strong{Visualization Data}: Provides ROC/PR curve data for \code{ggplot2} plotting (required for Results section).
\item \strong{Unbiased Evaluation}: Uses only the hold-out test set (15\% of input data) to avoid overestimating performance.
}
}
\examples{
# Load preprocessed data, train model, and evaluate
cleaned_data <- preprocess_heart_data("data/heart_data.csv")
cvd_model <- train_cvd_rf(cleaned_data)
eval_results <- evaluate_cvd_model(cvd_model)

# Print key metrics (for report)
cat("Test Set AUROC:", round(eval_results$auroc, 3), "\n")
cat("Test Set AUPRC:", round(eval_results$auprc, 3), "\n")
print(eval_results$confusion_matrix)

# Plot ROC curve (for Results section)
library(ggplot2)
ggplot(eval_results$roc_curve_data, aes(x = FPR, y = TPR)) +
  geom_line(linewidth = 1.2, color = "blue") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray") +
  labs(title = "ROC Curve (Test Set)",
       subtitle = paste("AUROC =", round(eval_results$auroc, 3)),
       x = "False Positive Rate", y = "True Positive Rate") +
  theme_classic()
}
